{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Scikit-learn for Classification Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Scikit-learn` is a Python library used for machine learning.  It features various classification and regression algorithms.  To use `Scikit-learn` to model data, you must import the desired algorithm and evaluation metric from the library. Evaluation metrics will be explained a bit later.\n",
    "<br><br>\n",
    "**For example:** Let's suppose we want to make a prediction using a Logistic Regression model with accuracy as our evaluation metric.  Then your imports would look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The 3rd import is our Logistic Regression algorithm import.\n",
    "- The 2nd import is our evaluation metric import.\n",
    "- The 1st import is a method for splitting our data randomly into train and test subsets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation metrics** tell us how `good` our model is.  Though there are other types of evaluation metrics for classification models, we will only use `accuracy` as a measure of `goodness` of our model.\n",
    "<br><br>\n",
    "`Accuracy` is a measure of how often our model predicts correctly.  The higher the accuracy the better our model predicts. For example, if your accuracy measure is 0.778, this means:\n",
    "<br>77.8 PERCENT OF THE TIME YOUR MODEL PREDICTS CORRECTLY."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to note that once an algorithm is chosen and imported, it must be initialized before you can use it.  To initialize our Logisitic Regression algorithm we do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logistic_regression = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I am creating an instance of a Logistic Regression model and then assigning it to the variable  `logistic_regression` for use later.  There are arguments that can be passed into **LogisticRegression( )** to make your predictions better, but I will not discuss those."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's go over an example problem to detail the steps of using machine learning for making predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Machine Learning to Predict a Category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are an analyst for a credit card company. You obtain the following data regarding its customers:\n",
    "<br>\n",
    "- LIMIT_BAL: Amount of the credit given to a customer.\n",
    "- SEX: Customer's gender (1 = male; 2 = female). \n",
    "- EDUCATION: Customer's highest level of education completed (1 = graduate school; 2 = university; 3 = high school; 4 = others). \n",
    "- MARRIAGE: Customer's marital status (1 = married; 2 = single; 3 = others). \n",
    "- AGE: Customer's age (year). \n",
    "- PAY0 - PAY6: Customer's payment history characteristics (1 = payment delay for one month; 2 = payment delay for two months; . . .; 9 = payment delay for nine months and above. ).\n",
    "- BILL_AMT1 - BILL_AMT6: Amount of a customer's bill statement for 6 consecutive months. \n",
    "- PAY_AMT2 - PAY_AMT6: History of a customer's past credit card payments made towards the balance. \n",
    "- DEFAULT - Whether the customer defaulted on his payment (1 = Yes; 0 = No)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have stored this data as a CSV file on the Math@Work server.  Let's import this dataset into its own Pandas DataFrame named cc_default and then print the first 10 rows of our newly created DataFrame to the screen. Recall, we discussed importing data into a DataFrame in the Data Science workshop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4  \\\n",
      "0      20000    2          2         1   24      2      2     -1     -1   \n",
      "1     120000    2          2         2   26     -1      2      0      0   \n",
      "2      90000    2          2         2   34      0      0      0      0   \n",
      "3      50000    2          2         1   37      0      0      0      0   \n",
      "4      50000    1          2         1   57     -1      0     -1      0   \n",
      "5      50000    1          1         2   37      0      0      0      0   \n",
      "6     500000    1          1         2   29      0      0      0      0   \n",
      "7     100000    2          2         2   23      0     -1     -1      0   \n",
      "8     140000    2          3         1   28      0      0      2      0   \n",
      "9      20000    1          3         2   35     -2     -2     -2     -2   \n",
      "\n",
      "   PAY_5   ...     BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  \\\n",
      "0     -2   ...             0          0          0         0       689   \n",
      "1      0   ...          3272       3455       3261         0      1000   \n",
      "2      0   ...         14331      14948      15549      1518      1500   \n",
      "3      0   ...         28314      28959      29547      2000      2019   \n",
      "4      0   ...         20940      19146      19131      2000     36681   \n",
      "5      0   ...         19394      19619      20024      2500      1815   \n",
      "6      0   ...        542653     483003     473944     55000     40000   \n",
      "7      0   ...           221       -159        567       380       601   \n",
      "8      0   ...         12211      11793       3719      3329         0   \n",
      "9     -1   ...             0      13007      13912         0         0   \n",
      "\n",
      "   PAY_AMT3  PAY_AMT4  PAY_AMT5  PAY_AMT6  DEFAULT  \n",
      "0         0         0         0         0        1  \n",
      "1      1000      1000         0      2000        1  \n",
      "2      1000      1000      1000      5000        0  \n",
      "3      1200      1100      1069      1000        0  \n",
      "4     10000      9000       689       679        0  \n",
      "5       657      1000      1000       800        0  \n",
      "6     38000     20239     13750     13770        0  \n",
      "7         0       581      1687      1542        0  \n",
      "8       432      1000      1000      1000        0  \n",
      "9         0     13007      1122         0        0  \n",
      "\n",
      "[10 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "cc_default = pd.read_csv('https://mathatwork.org/DATA/cc-default.csv')\n",
    "print(cc_default.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You decide that using the first 23 columns above will be sufficient to predict the last column, DEFAULT for future customers.  That is, given this input data, we can create a model for predicting the credit card default of a brand new customer.  Will a future customer default?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**STEP 1:**  Decide on an algorithm.\n",
    "<br>\n",
    "You decide to make the prediction using a Logistic Regression model with accuracy as your evaluation metric. Note that Logistic Regression is an appropriate model because we want to predict a category: Default? Yes/No?\n",
    "<br><br>\n",
    "Here is your initial code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logistic_regression = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**STEP 2:** Split your data into test and training subsets.\n",
    "<br><br>\n",
    "We will do this using a pretty cool method we imported from the `Scikit-learn` library, **train_test_split( )**. But first, we need to define X and y.  \n",
    "- X is the features you are using to make the prediction\n",
    "- y is the feature you are trying to predict\n",
    "<br><br>\n",
    "As stated above, your X is the first 23 columns and your y is the DEFAULT column.  Let's slice our DataFrame to get X.  Since this is a DataFrame, the process is a bit different than how you would slice a Numpy array (as discussed in the Data Science workshop):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4  \\\n",
      "0      20000    2          2         1   24      2      2     -1     -1   \n",
      "1     120000    2          2         2   26     -1      2      0      0   \n",
      "2      90000    2          2         2   34      0      0      0      0   \n",
      "3      50000    2          2         1   37      0      0      0      0   \n",
      "4      50000    1          2         1   57     -1      0     -1      0   \n",
      "\n",
      "   PAY_5    ...     BILL_AMT3  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  \\\n",
      "0     -2    ...           689          0          0          0         0   \n",
      "1      0    ...          2682       3272       3455       3261         0   \n",
      "2      0    ...         13559      14331      14948      15549      1518   \n",
      "3      0    ...         49291      28314      28959      29547      2000   \n",
      "4      0    ...         35835      20940      19146      19131      2000   \n",
      "\n",
      "   PAY_AMT2  PAY_AMT3  PAY_AMT4  PAY_AMT5  PAY_AMT6  \n",
      "0       689         0         0         0         0  \n",
      "1      1000      1000      1000         0      2000  \n",
      "2      1500      1000      1000      1000      5000  \n",
      "3      2019      1200      1100      1069      1000  \n",
      "4     36681     10000      9000       689       679  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "X = cc_default.loc[:,'LIMIT_BAL':'PAY_AMT6']\n",
    "print(X.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used the **loc[ ]** method on the `cc_default` DataFrame to slice all rows and all columns from LIMIT_BAL to PAY_AMT_6 into a new DataFrame, X."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's slice our DataFrame to get y.  That is, use the **loc[ ]** method on the cc_default DataFrame to slice all rows and only the DEFAULT column into a new DataFrame, y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    1\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "Name: DEFAULT, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "y = cc_default.loc[:,'DEFAULT']\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use the **train_test_split( )** method to split our data (X and y) into test and training subsets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since `test_size=0.20` was passed into our method, it specifies that we want 20% of the data in a test set and subsequently 80% of the data in a training set.  This data selection is done randomly by **train_test_split( )**.  In general, 80/20 is a good split.\n",
    "<br><br>\n",
    "We have done this for both our X and y DataFrames and defined X_train, X_test, y_train and y_test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**STEP 3:**  Use the training data to train your model.\n",
    "<br><br>\n",
    "That is, we will use X_train and y_train as inputs so that our Logistic Regression algorithm can find a pattern in which to make our prediction.  This training is done by passing the train data into the **fit( )** method applied to our `logistic_regression( )` algorithm defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no output here, but know that our model is all trained and ready to be evaluated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**STEP 4:** Use the test data to evaluate the model.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is, we will use X_test to make predictions about y and then compare y_test to these predicted y values.  Remember our evaluation metric will be `accuracy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.780666666667\n"
     ]
    }
   ],
   "source": [
    "y_predicted = logistic_regression.predict(X_test)\n",
    "eval_metric = accuracy_score(y_pred = y_predicted, y_true = y_test)\n",
    "print(eval_metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result tells us that the Logistic Regression algorithm 78% of the time predicts credit card default correctly.  100% is the best, but 78% is very good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before moving to the last step of making our prediction, remember that we want to pick the BEST model to make our prediction.  Here, the Logistic Regression model was very good, but is it the BEST?  To determine this, we have to re-do all the above steps for different classification models and then compare their accuracies.  Whichever one has the highest accuracy wins!\n",
    "<br><br>\n",
    "We will do this in part 2 of this notebook, `Scikit-Learn-Classification2.ipynb`.  See you there!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
